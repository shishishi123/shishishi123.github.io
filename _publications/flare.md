---
title: "FLARE: Defending Federated Learning against Model Poisoning Attacks via Latent Space Representations"
collection: publications
permalink: /publication/flare.pdf
excerpt: 'This paper proposes a robust aggregation algorithm FLARE to protect FL against MPAs. Through analysis and experimental visualization, we demonstrate that PLR vector has high potentials in differentiating malicious/poisonous models from the benign ones. FLARE effectively minimizes the impact of malicious/poisonous models on the final aggregation by assigning low trust scores to those with diverging PLRs. '
date: 2022-5-30
venue: '17th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2022)'
paperurl: 'http://academicpages.github.io/files/flare.pdf'
citation: 'N. Wang, Y. Xiao, Y. Chen, Y. Hu, W. Lou and Y.T. Hou, “FLARE: Defending Federated Learning against Model Poisoning Attacks via Latent Space Representations,” Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security, May 30–June 3, 2022, Nagasaki, Japan. ACM, 13 pages. https://doi.org/10.1145/3488932.3517395.'
---



[Download paper here](http://ning-wang1.github.io/files/flare.pdf)

Recommended citation: N. Wang, Y. Xiao, Y. Chen, Y. Hu, W. Lou and Y.T. Hou, “FLARE: Defending Federated Learning against Model Poisoning Attacks via Latent Space Representations,” Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security, May 30–June 3, 2022, Nagasaki, Japan. ACM, 13 pages. https://doi.org/10.1145/3488932.3517395.
